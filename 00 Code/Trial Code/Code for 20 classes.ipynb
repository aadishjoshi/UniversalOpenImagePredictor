{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import gc\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "inception_v3() missing 1 required positional argument: 'inputs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-2a33de4714bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minception_v3\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minception_v3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minception_v3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: inception_v3() missing 1 required positional argument: 'inputs'"
     ]
    }
   ],
   "source": [
    "#----------------------Inception model handling ---------------\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "sys.path.append('C:/Users/aadis/Documents/Anaconda WorkSpace/TensorFlow/Universal OpenImage Predictor/models/research/slim/')\n",
    "from nets import inception_v3\n",
    "\n",
    "model = inception_v3.inception_v3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(image_path):\n",
    "    \n",
    "    # Use the Inception model to classify the image.\n",
    "    pred = model.classify(image_path=image_path)\n",
    "\n",
    "    # Print the scores and names for the top-10 predictions.\n",
    "    model.print_scores(pred=pred, k=10, only_first_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('E:/Datasets/validation-annotations-human-imagelabels.csv', usecols=[0,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.Confidence == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['/m/0k5j', '/m/015y8h', '/m/018rqw', ..., '/m/04p33s', '/m/0c40t',\n",
       "       '/m/06_knc'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.LabelName.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.array(['/m/01g317', '/m/09j2d', '/m/04yx4', '/m/0dzct', '/m/07j7r', '/m/05s2s', '/m/03bt1vf', '/m/07yv9', '/m/0cgh4', '/m/01prls', '/m/09j5n', '/m/0jbk', '/m/0k4j', '/m/05r655', '/m/02wbm', '/m/0c9ph5', '/m/083wq', '/m/0c_jw', '/m/03jm5', '/m/0d4v4'])\n",
    "\n",
    "#**************Notes***********\n",
    "#/m/01g317 : Bittern\n",
    "#/m/09j2d    Clothing\n",
    "#/m/04yx4\n",
    "#/m/0dzct    Human face\n",
    "#/m/07j7r   Tree\n",
    "#/m/05s2s    Plant\n",
    "#/m/03bt1vf\n",
    "#/m/07yv9    Vehicle\n",
    "#/m/0cgh4     Building\n",
    "#'/m/01prls', Land vehicle \n",
    "#'/m/09j5n'   Footwear\n",
    "#'/m/0jbk'    Animal\n",
    "#'/m/0k4j',    Car\n",
    "# '/m/05r655'\n",
    "#'/m/02wbm',   Food\n",
    "#'/m/0c9ph5'   Flower\n",
    "#'/m/083wq'    Wheel\n",
    "#/m/0c_jw'     Furniture\n",
    "#'/m/03jm5'    House\n",
    "#'/m/0d4v4'    Window\n",
    "#####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageID</th>\n",
       "      <th>LabelName</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8b349b63e4385558</td>\n",
       "      <td>/m/0k4j</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1158ff693584049b</td>\n",
       "      <td>/m/07yv9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1eb5447743b21204</td>\n",
       "      <td>/m/02wbm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9822a048d45b5139</td>\n",
       "      <td>/m/01prls</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2a19b4586ac1052e</td>\n",
       "      <td>/m/07yv9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ImageID  LabelName  Confidence\n",
       "0  8b349b63e4385558    /m/0k4j           1\n",
       "1  1158ff693584049b   /m/07yv9           1\n",
       "2  1eb5447743b21204   /m/02wbm           1\n",
       "3  9822a048d45b5139  /m/01prls           1\n",
       "4  2a19b4586ac1052e   /m/07yv9           1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li = []\n",
    "for i in classes:\n",
    "    li.append(df[df.LabelName == i])\n",
    "df = pd.concat(li).sample(frac=1).reset_index(drop=True)\n",
    "del li\n",
    "gc.collect()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68867\n"
     ]
    }
   ],
   "source": [
    "labels = df.LabelName.tolist()\n",
    "Imageid = df.ImageID.values\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.layers import Dense, Conv2D, PReLU, BatchNormalization, MaxPooling2D, Dropout, Flatten\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras.models import load_model, Sequential\n",
    "from tqdm import tqdm_notebook\n",
    "from tqdm import tqdm\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(            ImageID  LabelName  Confidence\n",
       " 0  8b349b63e4385558    /m/0k4j           1\n",
       " 1  1158ff693584049b   /m/07yv9           1\n",
       " 2  1eb5447743b21204   /m/02wbm           1\n",
       " 3  9822a048d45b5139  /m/01prls           1\n",
       " 4  2a19b4586ac1052e   /m/07yv9           1, 0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(),gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]C:\\Users\\aadis\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image.py:492: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n",
      "100%|██████████| 1000/1000 [01:36<00:00, 12.63it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train = [np.array(load_img('E:/Datasets/validation/{}.jpg'.format(i),target_size=(100,100), grayscale=True))/255 for i in tqdm(Imageid[10000:11000])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]C:\\Users\\aadis\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image.py:492: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n",
      "100%|██████████| 200/200 [00:15<00:00, 10.69it/s]\n"
     ]
    }
   ],
   "source": [
    "X_Val = [np.array(load_img('E:/Datasets/validation/{}.jpg'.format(i),target_size=(100,100), grayscale=True))/255 for i in tqdm(Imageid[:200])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 142945.40it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 200157.67it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9, array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0.]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = classes.tolist()\n",
    "Y_train, Y_Val = [], []\n",
    "for i in tqdm(labels[10000:11000]):\n",
    "    temp = np.zeros(20)\n",
    "    temp[classes.index(i)] = 1\n",
    "    Y_train.append(temp)\n",
    "    del temp\n",
    "for i in tqdm(labels[:200]):\n",
    "    temp = np.zeros(20)\n",
    "    temp[classes.index(i)] = 1\n",
    "    Y_Val.append(temp)\n",
    "    del temp\n",
    "Y_train = np.array(Y_train)\n",
    "Y_Val = np.array(Y_Val)\n",
    "gc.collect(), Y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = Sequential()\n",
    "nn.add(BatchNormalization(input_shape=(100, 100, 1)))\n",
    "nn.add(Conv2D(4, kernel_size=(2,2), strides=(1,1)))\n",
    "nn.add(PReLU())\n",
    "nn.add(BatchNormalization())\n",
    "nn.add(Dropout(0.25))\n",
    "nn.add(Conv2D(8, kernel_size=(2,2), strides=(1,1)))\n",
    "nn.add(PReLU())\n",
    "nn.add(BatchNormalization())\n",
    "nn.add(Dropout(0.25))\n",
    "nn.add(Conv2D(16, kernel_size=(2,2), strides=(2,2)))\n",
    "nn.add(PReLU())\n",
    "nn.add(BatchNormalization())\n",
    "nn.add(Dropout(0.25))\n",
    "nn.add(Conv2D(32, kernel_size=(2,2), strides=(1,1)))\n",
    "nn.add(PReLU())\n",
    "nn.add(BatchNormalization())\n",
    "nn.add(Dropout(0.25))\n",
    "nn.add(Conv2D(32, kernel_size=(2,2), strides=(2,2)))\n",
    "nn.add(PReLU())\n",
    "nn.add(BatchNormalization())\n",
    "nn.add(Dropout(0.25))\n",
    "nn.add(Conv2D(32, kernel_size=(2,2), strides=(2,2)))\n",
    "nn.add(PReLU())\n",
    "nn.add(BatchNormalization())\n",
    "nn.add(Dropout(0.25))\n",
    "nn.add(Flatten())\n",
    "nn.add(Dense(2048))\n",
    "nn.add(PReLU())\n",
    "nn.add(BatchNormalization())\n",
    "nn.add(Dropout(0.25))\n",
    "nn.add(Dense(1024))\n",
    "nn.add(PReLU())\n",
    "nn.add(BatchNormalization())\n",
    "nn.add(Dropout(0.25))\n",
    "nn.add(Dense(512))\n",
    "nn.add(PReLU())\n",
    "nn.add(BatchNormalization())\n",
    "nn.add(Dropout(0.25))\n",
    "nn.add(Dense(128))\n",
    "nn.add(PReLU())\n",
    "nn.add(BatchNormalization())\n",
    "nn.add(Dropout(0.25))\n",
    "nn.add(Dense(50))\n",
    "nn.add(PReLU())\n",
    "nn.add(BatchNormalization())\n",
    "nn.add(Dropout(0.25))\n",
    "nn.add(Dense(25))\n",
    "nn.add(PReLU())\n",
    "nn.add(BatchNormalization())\n",
    "nn.add(Dropout(0.25))\n",
    "nn.add(Dense(20, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.compile(loss=keras.losses.categorical_crossentropy, metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train).reshape((1000,100,100,1))\n",
    "X_Val = np.array(X_Val).reshape((200,100,100,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 200 samples\n",
      "Epoch 1/5\n",
      " - 217s - loss: 3.6521 - acc: 0.0500 - val_loss: 3.3259 - val_acc: 0.0250\n",
      "Epoch 2/5\n",
      " - 198s - loss: 3.5306 - acc: 0.0520 - val_loss: 3.5755 - val_acc: 0.0150\n",
      "Epoch 3/5\n",
      " - 197s - loss: 3.4668 - acc: 0.0670 - val_loss: 3.7252 - val_acc: 0.0350\n",
      "Epoch 4/5\n",
      " - 202s - loss: 3.3994 - acc: 0.0710 - val_loss: 4.2698 - val_acc: 0.0400\n",
      "Epoch 5/5\n",
      " - 203s - loss: 3.2725 - acc: 0.0720 - val_loss: 6.0686 - val_acc: 0.0600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21cef5c1898>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit(X_train, Y_train, validation_data=(X_Val,Y_Val), batch_size=100, epochs=5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74377"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del X_train, Y_train, X_Val, Y_Val, df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2b2b327132556c767a736b3d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2b2b394755692f303963553d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2b2b42584e6d445937444d3d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2b2b44744e57674270616f3d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2b2b4b425a592b683059493d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   image_id\n",
       "0  2b2b327132556c767a736b3d\n",
       "1  2b2b394755692f303963553d\n",
       "2  2b2b42584e6d445937444d3d\n",
       "3  2b2b44744e57674270616f3d\n",
       "4  2b2b4b425a592b683059493d"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('E:/Datasets/all/stage_1_sample_submission.csv', usecols=[0])\n",
    "im = df.image_id.tolist()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a074f628a654866b23374fbfedb6043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=32580), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aadis\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image.py:492: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm_notebook(im):\n",
    "    try: \n",
    "        X_test = np.array(load_img('E:/Datasets/all/stage_1_test_images/{}.jpg'.format(i),target_size=(100,100), grayscale=True))/255\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(X_test).reshape((1,100,100,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre = nn.predict(X_test).argsort(1)[:,:5]\n",
    "del X_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1 16  8  5  6]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "p = []\n",
    "print(pre)\n",
    "for it in tqdm(pre):\n",
    "    p.append([classes[int(i)] for i in it])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['/m/09j2d', '/m/083wq', '/m/0cgh4', '/m/05s2s', '/m/03bt1vf']]\n"
     ]
    }
   ],
   "source": [
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/m/09j2d', '/m/083wq', '/m/0cgh4', '/m/05s2s', '/m/03bt1vf']\n"
     ]
    }
   ],
   "source": [
    "print(p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/m/09j2d', '/m/083wq', '/m/0cgh4', '/m/05s2s', '/m/03bt1vf']\n"
     ]
    }
   ],
   "source": [
    "p1 = str(p[0])\n",
    "print(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/m/09j2d\n",
      "Clothing\n",
      "/m/083wq\n",
      "Wheel\n",
      "/m/0cgh4\n",
      "Building\n",
      "/m/05s2s\n",
      "Plant\n"
     ]
    }
   ],
   "source": [
    "class_description = pd.read_csv('E:/Datasets/all/class-descriptions.csv', usecols=[0,1])\n",
    "label_list = class_description.label_code.tolist()\n",
    "\n",
    "for i in p[0]:\n",
    "    for k in range(0,len(class_description.label_code)):\n",
    "        j = class_description.label_code[k]\n",
    "        if i == j:\n",
    "            print(j)\n",
    "            print(class_description.description[k])\n",
    "            break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LightAug = Compose([\n",
    "      CLAHE(),\n",
    "      HorizontalFlip(.5),\n",
    "      ShiftScaleRotate(shift_limit=0.075, scale_limit=0.15, rotate_limit=10, p=.75 ),\n",
    "      Blur(blur_limit=3, p=.33),\n",
    "      OpticalDistortion(p=.33),\n",
    "      GridDistortion(p=.33),\n",
    "      HueSaturationValue(p=.33)\n",
    "  ], p=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
